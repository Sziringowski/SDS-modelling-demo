# Моделирование Системы Хранения Данных - демонстрационная версия

## User Story

*Я, как* product owner *хочу* иметь возможность расчитывать производительность из параметров железа  
*Чтобы* снизить затраты производства и повысить предсказуемость характеристик продукта

## Критерии приёмки

* Реализован инструмент анализа данных со следующей функциональностью:

    * проведение исследование данных на корреляцию, влияние на таргет;
    * изображение распределения данных;
    * изображение сравнительных графиков: сырой даты и предсказанной.

* Реализован инструмент моделирования со следующей функциональностью:

    * вывод метрик модели $R^2$, MAE, RMSE;
    * экстраполяция данных на интервал 4 - 100 узлов;
    * выявление влияния отдельных конфигурационных параметров;
    * изображение графиков предсказания / сырых данных.

* Реализована внутренняя система хранения со следующей функциональностью:

    * скриптовая выгрузка замеренной даты формата .txt/.md в .xlsx таблицу;
    * загрузка (с дубликатами / без дубликатов) замеров (замеры поступают постепенно, возможно, с дубликатами, поэтому валидация на дубликаты важна);
    * валидация на соответствие с бизнес - логикой пакет замеров перед отправкой во внутреннюю систему хранения.

## Термины и понятия

* **проект** - совокупность скриптов, инструментов, базы данных, архитектуры и документации
* **замер** - файл с фичами и значением производительности СХД, полученном при нагрузочном тестировании
* **фичи** - набор конфигурационных параметров замера
* **тагрет** - производительность Системы Хранения Данных, целевое значение  
* **модель** - метод и набор параметров, функция, принимающая на вход фичи и выдающая таргет

## Структура проекта

- **sds-modelling/**  
    - readme.md
    - spec.md
    - model.ipynb *- инструмент моделирования*
    - analysis.ipynb *- инструмент анализа данных*
    - **outputs/** *- артефакты работы софта*
        - broken_sizes.xlsx
        - output.xlsx
    - **scripts/**
        - __init\__.py *- инициатор пакета*
        - data_preprocessing.py *- скрипты предобработки и записи данных*
        - documentation.py *- документирвоание фичей и глобальных переменных*
        - modelling.py *- скрипты моделирования*
        - database_management.py *- инструмены управления БД*
    - **sizes/**
        - \*size.md *- замеры*

## Реализация проекта

**Концепция** - абстракция в классах, унификация проекта и автоматизация рутины.

_Проект реализован в соответствии с принципами ООП, разделение по модулям происходило из выполняемых классами модулей функциям._

### модуль `documentation`

модуль, в котором фиксируются свойства и именования всех сущностей с которыми в дальнейшем осуществляется работа.

### модуль `database_management`

* класс `database` - объект базы данных, обеспечивающий соединение и доступ к CRD - действиям с БД.

    * атрибуты - креды коннекта с БД:

        * `dbname`
        * `user`
        * `password`
        * `host`
        * `port`

    * методы:

        * `PUT` - запись в БД, есть опция валидации данных на исключение повторной записи, возможно отключение валидации
        * `GET` - получения записи из БД
        * `DELETE` - удалени записи из БД по `id`

### модуль `data_preprocessing`

* класс `file_data_proccesor` - объект обработчика поступающих замеров, осуществляет валидацию на соответствие с бизнес - логикой

    * атрибуты:

        * `path` - путь до файла для чтения
        * `Data` - таргет атрибут класса
        * `uploaded_strings` - добавленные записи
        * `correct_number_of_sizes` - кол-во замеров
        * `database` - инстанс БД
        * `cleared_data` - очищенная дата
        * `removed_data` - удалённые точки

    * методы:

        * `_read` - чтение записей из .txt/.md файла замеров
        * `_founder` - скрипт поиска замеров, не подходящих по бизнес - логике
        * `_auto_cleaner` - автоочистка пачки замеров от данных, не подходящих по бизнес - логике, возможно отключение валидации
        * `write` - запись прочитанных и обработанных замеров в БД

* класс `data_instance` - объект данных
    
    * атрибуты: 

        * `data_df` - данные
        * `data_df_ohe` - данные после OHE 
        * `database` - инстанс БД
        * `encoded_features` - категориальные атрибуты после OHE

    * методы: 
        * `correlation_matrix` - корреляционная матрица фичей
        * `correlation_matrix_to_target` - корреляционная матрица фичей к таргету
        * `ohe` - OneHotEncoder для фичей
        * `distribution` - распределение фичей
        * `compare_graphs` - графики для двух наборов параметров и numerical - параметра, вдоль которого строятся графики 

### модуль `modelling`

* класс `grid`

    * атрибуты:

        * `database` - инстанс БД
        * `lines` - массив сгенерированных данных
        * `iterations` - кол-во полных циклов генерации синтетики
        * `circle_accept` - количество допустимых циклов при генерации данных

    * методы:

        * `_synth_generation` - генерация синтетики
        * `write` - запись в БД синтетических данных
        * `read` - чтение внешних синтетических данных
        * `compare_graphs` - графики для двух наборов параметров и numerical - параметра, вдоль которого строятся графики для синтетики
        * `GET` - получение записи из массива синтетики

* класс `catboost_model`

    * атрибуты:

        * `n_trials`  # колво итераций прототипирования
        * `data_df_prototyping` - датасет для прототипировани с optune
        * `seed` - сид случайных операций
        * `data_df_learn` - датасет для обучения модели после протипирования
        * `best_params` - лучшие параметры при прототипировании
        * `model_metrics` - метрики модели
        * `cv` - количество фолдов кросс - валидация
        * `model` - обученная модель

    * методы:

        * `prototyping` - создание прототипа CatBoostRegressor, подбор гиперпараметров с optune
        * `train` - обучение модели на подобранных параметрах
        * `predict` - предсказание со встроенным энкодингом данных
        * `compare_graphs` - выведение графиков синтетики и предсказанных данных (и сырых данных, при существовании)

* класс `NN_model`

    * атрибуты:

        * `data_df_prototyping` - датасет для прототипировани с optune
        * `seed` - сид случайных операций
        * `data_df_learn` - датасет для обучения модели после протипирования
        * `best_params` - лучшие параметры при прототипировании
        * `model_metrics` - метрики модели
        * `model` - обученная модель
        * `encoder` - обученный OHE

    * методы:

        * `prototyping` - создание прототипа NN, подбор гиперпараметров и архитектуры сети
        * `train` - обучение NN на подобранных параметрах
        * `predict` - предсказание со встроенным энкодингом данных
        * `compare_graphs` - выведение графиков синтетики и предсказанных данных (и сырых данных, при существовании)

### База данных

В качестве СУБД выбран PostgreSQL, фреймворк - `psycopg2`, существует интерфейс взаимодействия с БД.

* Таблица `sizes`

<table>
  <tr>
    <td>Системное наименование</td>
    <td>Тип данных</td>
  </tr>
  <tr>
    <td>id</td>
    <td>text</td>
  </tr>
  <tr>
    <td>protection</td>
    <td>text</td>
  </tr>
  <tr>
    <td>size</td>
    <td>int</td>
  </tr>
  <tr>
    <td>nodes</td>
    <td>int</td>
  </tr>
  <tr>
    <td>op_type</td>
    <td>text</td>
  </tr>
  <tr>
    <td>hw_chassis</td>
    <td>text</td>
  </tr>
  <tr>
    <td>ssd</td>
    <td>int</td>
  </tr>
  <tr>
    <td>mbps</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>avg</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>min</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>med</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>max</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>p90</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>p95</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>opps</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>opps_loss</td>
    <td>real[]</td>
  </tr>
  <tr>
    <td>sum_mbps</td>
    <td>real</td>
  </tr>
  <tr>
    <td>sum_opps</td>
    <td>real</td>
  </tr>
  <tr>
    <td>path</td>
    <td>text</td>
  </tr>
</table>


* Таблица `sizes_synthetic`


<table>
  <tr>
    <td>Системное наименование</td>
    <td>Тип данных</td>
  </tr>
  <tr>
    <td>id</td>
    <td>text</td>
  </tr>
  <tr>
    <td>protection</td>
    <td>text</td>
  </tr>
  <tr>
    <td>size</td>
    <td>int</td>
  </tr>
  <tr>
    <td>nodes</td>
    <td>int</td>
  </tr>
  <tr>
    <td>op_type</td>
    <td>text</td>
  </tr>
  <tr>
    <td>hw_chassis</td>
    <td>text</td>
  </tr>
  <tr>
    <td>ssd</td>
    <td>int</td>
  </tr>
  <tr>
    <td>sum_mbps</td>
    <td>real</td>
  </tr>
  <tr>
    <td>sum_opps</td>
    <td>real</td>
  </tr>
  <tr>
    <td>r2</td>
    <td>real</td>
  </tr>
  <tr>
    <td>mse</td>
    <td>real</td>
  </tr>
  <tr>
    <td>mae</td>
    <td>real</td>
  </tr>
</table>

### Модель

Представлены две модели - ансамблевая CatBoostRegressor библиотеки `catboost` и полносвязная нейронная сеть на `tensorflow`.  
Перед обучением моделей были сгенерированы синтетические данные с использованием линейных регрессионных и аналитических моделей проводящих экстраполяцию вдоль количества нод (`nodes`) и размера файла (`size`) соответственно. Проведена работа над данными: выделены новые признаки, обработаны категориальные.  
По результатам экспериментов предпочтение отдано нейросети - эта модель наиболее удачно улавливает паттерны в сырых и синтетических данных.
